{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stonkmem/stonkmem/blob/main/08_Unsupervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COPY THIS NOTEBOOK BEFORE DELETING THIS LINE"
      ],
      "metadata": {
        "id": "Q8_TSTrE0qGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning"
      ],
      "metadata": {
        "id": "8OhhZb1iol5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Import Stuff"
      ],
      "metadata": {
        "id": "IM91oDnMr-59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.datasets import make_blobs"
      ],
      "metadata": {
        "id": "3Qw2o3AboswB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. K-means"
      ],
      "metadata": {
        "id": "dUNnSUK-sB2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans(data, k=3, max_iters=100):\n",
        "    # 1. Randomly initialize centroids (pick k unique points from data)\n",
        "    centroids = data[___]  # Hint: Use torch.randperm\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        # 2. Assign each point to the nearest centroid (use torch.cdist)\n",
        "        distances = ___(data, centroids)\n",
        "        clusters = torch.argmin(___, dim=___)\n",
        "\n",
        "        # 3. Update centroids (mean of points in each cluster)\n",
        "        new_centroids = torch.stack([\n",
        "            ___ for i in range(k)  # Hint: Filter data by cluster\n",
        "        ])\n",
        "\n",
        "        # 4. Stop if centroids don't change\n",
        "        if torch.allclose(___, ___):\n",
        "            break\n",
        "        centroids = ___\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "# Test on synthetic data\n",
        "data = torch.randn(300, 2)\n",
        "clusters, centroids = kmeans(___, k=3)"
      ],
      "metadata": {
        "id": "fWO01QfzoqBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(data[:, 0], data[:, 1], c=clusters)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LZ2vSZ6O1E4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PCA"
      ],
      "metadata": {
        "id": "COG0Tf3PswGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ZVl-Gmiryx"
      },
      "outputs": [],
      "source": [
        "def pca(data, k=2):\n",
        "    # 1. Center the data (subtract mean)\n",
        "    data_centered = (___ - data.___(___)) / data.___(___)\n",
        "\n",
        "    # 2. Compute covariance matrix (X^T X / n)\n",
        "    cov = torch.matmul(___.T, ___) / len(___)\n",
        "\n",
        "    # 3. Eigen decomposition (use torch.linalg.eigh)\n",
        "    eigenvalues, eigenvectors = ___(___)\n",
        "\n",
        "    # 4. Sort eigenvectors by eigenvalues (descending)\n",
        "    sorted_indices = torch.argsort(___, descending=___)\n",
        "    top_k_eigenvectors = eigenvectors[:, ___][:, :k]\n",
        "\n",
        "    # 5. Project data onto top-k eigenvectors\n",
        "    reduced_data = torch.matmul(___, ___)\n",
        "    return reduced_data\n",
        "\n",
        "# Test on Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "data = torch.FloatTensor(iris.data)\n",
        "reduced_data = pca(___, k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Visualisation"
      ],
      "metadata": {
        "id": "00FpFfKPs0A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## K-means\n",
        "### Generate synthetic data\n",
        "data = torch.randn(150, 2)\n",
        "clusters, centroids = kmeans(data, k=3)\n",
        "\n",
        "### Plot\n",
        "plt.scatter(data[:, 0], data[:, 1], c=clusters, cmap='viridis')\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], marker='X', s=200, c='red')\n",
        "plt.title(\"K-Means Clustering\")\n",
        "plt.show()\n",
        "\n",
        "## PCA\n",
        "### Standardize and reduce data\n",
        "reduced_data = pca(data, k=2)\n",
        "\n",
        "### Plot\n",
        "plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=clusters, cmap='viridis')\n",
        "plt.xlabel('PC1'); plt.ylabel('PC2')\n",
        "plt.title(\"PCA Projection\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z5ePUfrns42V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6Nx7T9Wes4hM"
      }
    }
  ]
}